---
title: "PPHA 30538 Final Project Plot 1"
author: "Amulya Jasti (amjamz, Sec. 4), Sitong Guo (AnthonySigmar, Sec. 4), Helen Liu (helenriv, Sec. 3)"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

```{python}
import geopandas as gpd
import pandas as pd
import shapely
from shapely import wkt
from shapely.geometry import Point
import matplotlib.pyplot as plt
import contextily as cx
import altair as alt
import pyarrow
```

```{python}
#Can use these to change paths easily
aj_path = "C:/Users/amuly/OneDrive/Documents/GitHub/30538-finalproject-smartmeters/"
sg_path = "C:/Users/RedthinkerDantler/Documents/GitHub/DPPP2/30538-finalproject-smartmeters/"
hl_path = "Helen's basepath"
current_path = aj_path
```

Our smart meter data is from weave.energy and our shapefile data is from UK's National Energy System Operator (NESO).

Step 1: Import and clean the data

Source: https://github.com/centre-for-ai-and-climate/lv-feeder-smart-meter-data/blob/main/2024-02-12-aggregated-by-substation.csv.gz

```{python} 
#| eval: false

#import data aggregated by substation, and only select substations from UKPN
substations = pd.read_csv(r"C:\Users\amuly\Downloads\2024-02-12-aggregated-by-substation.csv\2024-02-12-aggregated-by-substation.csv")
substations_UKPN = substations[substations['substation'].str.startswith('UKPN', na=False)]
```

```{python}
#| eval: false

#save as CSV so partners can use it
substations_UKPN.to_csv("C:/Users/amuly/OneDrive/Documents/GitHub/30538-finalproject-smartmeters/data/substations_UKPN.csv", index=False)
```

```{python}
#import data
substations_UKPN = pd.read_csv(current_path+'data/substations_UKPN.csv')

#add new time columns to analyze
substations_UKPN['timestamp'] = pd.to_datetime(substations_UKPN['timestamp'])
substations_UKPN['date'] = substations_UKPN['timestamp'].dt.date
substations_UKPN['day_of_week'] = substations_UKPN['timestamp'].dt.day_name()
substations_UKPN['time_of_day'] = substations_UKPN['timestamp'].dt.time

#set up as a gdf
substations_UKPN['geometry'] = substations_UKPN.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)
substations_UKPN_gdf = gpd.GeoDataFrame(substations_UKPN, geometry='geometry')
substations_UKPN_gdf = substations_UKPN_gdf.set_crs("EPSG:4326", inplace=True)
```

Filtered to the Bedford/Cambridge region. Source: https://ukpowernetworks.opendatasoft.com/explore/dataset/ukpn-epn-area-operational-boundaries/information/

```{python}
epn_boundaries = gpd.read_file(current_path + "/data/ukpn-epn-area-operational-boundaries/ukpn-epn-area-operational-boundaries.shp")
bedford_cambridge = epn_boundaries[epn_boundaries['ops_area'] == 'Bedford/Cambridge']

# Spatial join to filter to substations from Bedford/Cambridge region
bedford_cambridge_substations = gpd.sjoin(
    substations_UKPN_gdf,  # Substation GeoDataFrame
    bedford_cambridge,     # Bedford/Cambridge region GeoDataFrame
    how='inner',
    predicate='within'
)

# clean substation column
bedford_cambridge_substations['substation'] = bedford_cambridge_substations['substation'].apply(lambda s: s[9:])
```

Added substation boundary data. Source: https://ukpowernetworks.opendatasoft.com/api/explore/v2.1/catalog/datasets/ukpn_secondary_postcode_area/records?limit=20&refine=dno%3A%22EPN%22

```{python}
# Step 1: Load substation boundary data
epn_substation_boundaries = gpd.read_file(current_path + "data/ukpn_secondary_postcode_area/ukpn_secondary_postcode_area.shp").rename(columns={
    "dno": "DNO",
    "sitefunctio": "site_functional_location",
    "demand_head": "demand_headroom",
    "onanrating": "ONAN_rating",
    "source": "source",
    "utilisation": "utilisation_band",
    "predicted_y": "predicted_year_of_reinforcement",
    "customer_co": "customer_count"
})

# Merge on substation column and sitefunctionallocation column
bedford_cambridge_substations = epn_substation_boundaries.merge(
    bedford_cambridge_substations, 
    left_on="site_functional_location", 
    right_on="substation", 
    how="inner", 
    suffixes=('_boundaries', '_substations')  # Suffixes for overlapping column names
)

#reassign geometry
bedford_cambridge_substations_gdf = gpd.GeoDataFrame(bedford_cambridge_substations, geometry='geometry_boundaries')
bedford_cambridge_substations_gdf.rename(columns={'geometry': 'old_geometry'}, inplace=True)
```

```{python}
#| eval: false
pd.DataFrame(bedford_cambridge_substations).to_csv(current_path + "data/bedford-cambridge-substations.csv")
```

Each of the observations in bedford_cambridge_substations_gdf is unique by substation and timestamp (every half hour) combination, with the following columns:
- substation: specific substation of the observation
- consumption: consumption in the past half-hour period
- timestamp: date and half-hour mark, in datetime format
- date: YYYY-MM-DD
- day_of_week: day of week in English (i.e. Monday, Tuesday, ...)
- time_of_day: HH:MM:SS (still in half hour intervals so either HH:00:00 or HH:30:00)
- geometry_boundaries: treated as geometry

Step 2: Plot average consumption by substation

```{python}
#Sample code: plot average consumption overall by substation
avg_consumption_by_substation = bedford_cambridge_substations_gdf.groupby('substation')['consumption'].mean().reset_index()

# merge the average consumption with the original GeoDataFrame based on the substation
bedford_cambridge_avg = bedford_cambridge_substations_gdf.merge(avg_consumption_by_substation[['substation', 'consumption']], on='substation', suffixes=('', '_avg'))

# average consumption by substation
ax = bedford_cambridge_avg.plot(
    marker='o', 
    markersize=3, 
    column='consumption_avg',
    cmap='magma', 
    legend=True, 
    legend_kwds={"label": "Average Consumption (kWh) by Substation in Bedford/Cambridge"},
    figsize=(10, 6)
)

cx.add_basemap(
    ax, 
    crs=bedford_cambridge_substations_gdf.crs.to_string(), 
    source=cx.providers.CartoDB.Voyager, 
    attribution=False
)

plt.show()
```

Step 3: Create time template for Shiny App
```{python}
#sample code: plot all substations' consumptions for 2024-02-12 00:30:00
time = '2024-02-12 00:30:00' #between this and end of 2024-02-29
ax = bedford_cambridge_substations_gdf[bedford_cambridge_substations_gdf['timestamp'] == time].plot(marker='o', markersize=3, column="consumption", cmap='magma', legend="true", legend_kwds={"label": "Total Consumption Active Import (kWh) on 2/12/24 at 12:30AM"}, figsize=(10, 6))
cx.add_basemap(ax, crs=bedford_cambridge_substations_gdf.crs.to_string(), source=cx.providers.CartoDB.Voyager, attribution=False) # adds basemap of UK
plt.show()
```

Step 4: Graph average by time of day

```{python}
alt.data_transformers.disable_max_rows()
average_consumption = substations_UKPN.groupby('time_of_day')['consumption'].mean().reset_index()
average_consumption['time_of_day'] = pd.to_datetime(average_consumption['time_of_day'], format='%H:%M:%S').dt.strftime('%H:%M:%S')

plot = alt.Chart(average_consumption).mark_line().encode(
    x=alt.X('time_of_day:N', title='Time of Day', axis=alt.Axis(labelAngle=-45, labelOverlap="greedy")),
    y=alt.Y('consumption:Q', title='Average Consumption')
).properties(
        width=900, #adjusted width to fit all labels
        title=f'Average Consumption by Time of Day across all UK Smart Meters'
    )
plot
```

```{python}
#| eval: false
save(plot, current_path + 'plots/average_consumption_plot.png', scale=2.0)
```
